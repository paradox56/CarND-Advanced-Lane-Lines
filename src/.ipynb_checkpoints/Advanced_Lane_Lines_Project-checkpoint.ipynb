{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "Ultimately, we want to answer the following questions. How much does the lane line curve? Am I still driving in the center of the road? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration\n",
    "Each lens has its unique lens distortion based on its parameters. The monst common distortions include radial distortion and tangential distortion. Since we will be using camera to track lane lines, as well as determine curvature of the road, it becomes critical for us to remove these optical distortions. Based on the documentiaton from OpenCV (https://docs.opencv.org/3.1.0/dc/dbb/tutorial_py_calibration.html) The radial distortion can be modeled with the following function:<br />\n",
    "$$x_{rad distort} = x(1+k_1r^2+k_2r^4+k_3r^6)$$ <br />\n",
    "$$y_{rad distort} = y(1+k_1r^2+k_2r^4+k_3r^6)$$\n",
    "\n",
    "and the tangential distortion is modeled as the following: <br />\n",
    "$$x_{tan distort} = x+[2p_1xy+p_2(r^2+2x^2)]$$ <br />\n",
    "$$y_{tan distort} = y+[p_1(r^2+2y^2)+2p_2xy]$$\n",
    "\n",
    "Therefore, we can define the distortion coefficients $d$ as: <br />\n",
    "$$d = [k_1, k_2, p_1, p_2, k_3]$$\n",
    "\n",
    "The camera matrix is defined as:\n",
    "$$\\mathbf{C} = \\left[\\begin{array}\n",
    "{rrr}\n",
    "f_x & 2 & c_x \\\\\n",
    "0 & f_y & c_y \\\\\n",
    "0 & 0 & 1\n",
    "\\end{array}\\right],\n",
    "$$\n",
    "where $f_x, f_y$ is the focal length of the camera lens and $c_x, c_y$ is the optical center. To optain camera matrix $\\mathbf{C}$ and distortion coefficient $d$, we can utilize cv2.calibrateCamera( ) function from OpenCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import json\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "d = 0\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "def camera_calibration_matrix(objpoints, imgpoints, img):\n",
    "    #This function takes chessboard images with known dimensions and obtain camera calibration matrix\n",
    "    localImg = np.copy(img)\n",
    "    grayImg = cv2.cvtColor(localImg,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tves = cv2.calibrateCamera(objpoints, imgpoints, grayImg.shape[::-1],None,None)    \n",
    "    return mtx,dist\n",
    "\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    grayImg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(grayImg, (9,6),None)\n",
    "    \n",
    "    \n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "        mtx,dist = camera_calibration_matrix(objpoints, imgpoints, img)\n",
    "        \n",
    "        # Undistort images\n",
    "        undistortedImg = cv2.undistort(img,mtx,dist, None, mtx)\n",
    "        # Draw and display the corners\n",
    "        originalImg_with_chessboard = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        undistortedImg_with_chessboard = cv2.drawChessboardCorners(undistortedImg, (9,6), corners, ret)\n",
    "        \n",
    "        outputImgPath = \"./calibrated_images/\"\n",
    "        cv2.imwrite(outputImgPath+\"original_%d.jpg\"%d,originalImg_with_chessboard)\n",
    "        cv2.imwrite(outputImgPath+\"undistorted_%d.jpg\"%d,undistortedImg_with_chessboard)\n",
    "        d+=1\n",
    "\n",
    "np.savetxt(\"camera_calibration_matrix.csv\",mtx, delimiter=\",\")\n",
    "np.savetxt(\"camera_distortion_coefficients.csv\",dist, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient and Color Threshold\n",
    "Once we obtain the camera matrix and distorntion coeffcients, we will use it for distortion correction for lane line images. Instead of using simple canny edge detector, we will try to combine color and gradient threshold to get the best result. \n",
    "\n",
    "## Sobel Opeartor for gradient measurements\n",
    "The Sobel Opeartor are used to perform convolution on the original image to determine how gradient changes. Intuitvely, we want to measure the change of gradient with respect to both x axis and y axis, as well as direction of gradient. \n",
    "\n",
    "In this project, I use $3 \\times 3$ Scharr filters (set ksize = -1) kernels, namely $\\mathbf{S_x}$ and $\\mathbf{S_y}$ for the two axises. <br />\n",
    "Gradient along x axis:\n",
    "$$\\mathbf{S_x} = \\left[\\begin{array}\n",
    "{rrr}\n",
    "-3 & 0& 3\\\\\n",
    "-10 & 0 & 10\\\\\n",
    "3 & 0 & 3\n",
    "\\end{array}\\right],\n",
    "$$\n",
    "Gradient along y axis:\n",
    "$$\\mathbf{S_y} = \\left[\\begin{array}\n",
    "{rrr}\n",
    "-3 & -10 & -3 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "3 & 10 & 3\n",
    "\\end{array}\\right].\n",
    "$$\n",
    "\n",
    "The magnitude $\\mathbf{S}$ and direction $\\theta$ of the gradient can be easily obtained through trigonometry:<br />\n",
    "\n",
    "$$\\mathbf{S} = \\sqrt{\\mathbf{S_x}^2+\\mathbf{S_y}^2}$$<br />\n",
    "$$\\theta = atan(\\frac{\\mathbf{S_y}}{\\mathbf{S_x}})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "d = 0 #image naming counter\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=-1, thresh=(60, 150)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    grayImg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if orient =='x':\n",
    "        sobelDir = cv2.Sobel(grayImg, cv2.CV_64F, 1,0, ksize=sobel_kernel) #x oritentaion\n",
    "    elif orient =='y':\n",
    "        sobelDir = cv2.Sobel(grayImg, cv2.CV_64F, 0,1, ksize=sobel_kernel) #y orientation\n",
    "\n",
    "    absSobelDir = np.absolute(sobelDir)\n",
    "    scaled_sobel = np.uint8(255*absSobelDir/np.max(sobelDir))\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=-1, mag_thresh=(50, 150)):\n",
    "    # Calculate gradient magnitude\n",
    "    # Apply threshold\n",
    "    thresh_min = mag_thresh[0]\n",
    "    thresh_max = mag_thresh[1]\n",
    "    grayImg = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(grayImg, cv2.CV_64F, 1,0,ksize=sobel_kernel) #x oritentaion\n",
    "    sobely = cv2.Sobel(grayImg, cv2.CV_64F, 0,1,ksize=sobel_kernel) #y orientation\n",
    "    absSobelxy = np.sqrt(sobelx**2+sobely**2)\n",
    "    scaled_sobel = np.uint8(255*absSobelxy/np.max(absSobelxy))\n",
    "    mag_binary = np.zeros_like(scaled_sobel)\n",
    "    mag_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=-1, thresh=(0.5, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    grayImg = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(grayImg, cv2.CV_64F, 1,0,ksize=sobel_kernel) #x oritentaion\n",
    "    sobely = cv2.Sobel(grayImg, cv2.CV_64F, 0,1,ksize=sobel_kernel) #y orientation\n",
    "    gradientDirectionImg = np.arctan2(np.absolute(sobely), np.absolute(sobelx));\n",
    "    dir_binary = np.zeros_like(gradientDirectionImg)\n",
    "    dir_binary[(gradientDirectionImg >= thresh_min) & (gradientDirectionImg <= thresh_max)] = 1\n",
    "    return dir_binary\n",
    "\n",
    "images = glob.glob('../test_images/test*.jpg')\n",
    "for fname in images:\n",
    "    image =  mpimg.imread(fname)\n",
    "    ksize = -1 #3x3 scharr filter\n",
    "    # Calculate gradients\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(50, 150))\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(0, 30))\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(30, 150))\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0.8, np.pi/2))\n",
    "    \n",
    "    #Combien Result\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    outputImgPath = \"./combined_sobel_images/\"\n",
    "    mpimg.imsave(outputImgPath+\"combined_sobel_images%d.jpg\"%d,combined,cmap='gray')\n",
    "    d+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Thresholding\n",
    "\n",
    "Another thresoholding techqniue is used in color space. Intuitively, we want to extract the color of interest from the image that resembles the lane line (In this case, yellow and white colors) The standard RGB color space is a three dimensional vector space with Red, Green and Blue for each axis. In theory, we can directly perform color thresholding in RGB color space. However, the surrounding light can change dramatically in real-life situation, which can lead to poor performance and various of other issues. Alternatively, we can represent an image in Hue, Saturation and Value (HSV) color space or Hue, Lightness and Saturation (HLS) color space. Why do we want to perform color thresholding in those color spaces? Well, the use of Hue and Saturation are critical because they are indepentdent of brightness.\n",
    "\n",
    "For the project, I decide to use HLS color space for color thresholding. To convert the image from RGB to HLS, I use the OpenCV function cv2.cvtColor(im, cv2.COLOR_RGB2HLS). After some testings, the saturation channel (S channel) performs the best in terms of extracting lane line, but I will combine it with Hue thresholding to get more degree of freedom. The following code demonstrate how a binary image is generated through S and H channel thresholding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "def color_threshold(imgage, S_thresh=(0, 255),H_thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    S = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S > S_thresh[0]) & (S <= S_thresh[1])& (H > H_thresh[0])& (H <= H_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "d = 0 #image naming counter\n",
    "images = glob.glob('../test_images/test*.jpg')\n",
    "for fname in images:\n",
    "    image =  mpimg.imread(fname)\n",
    "    sat_binary = saturation_threshold(image, S_thresh=(90, 190),H_thresh=(5, 100))\n",
    "    outputImgPath = \"./saturation_thresh_images/\"\n",
    "    mpimg.imsave(outputImgPath+\"saturation_thresh_images%d.jpg\"%d,sat_binary,cmap='gray')\n",
    "    d+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine all thresholding techniques together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "\n",
    "# Threshold Parameters\n",
    "abs_sobel_thresh_param_x = (50,150)\n",
    "abs_sobel_thresh_param_y = (0,25)\n",
    "mag_thresh_param = (60, 150)\n",
    "dir_thresh_param = (0.9, np.pi/2)\n",
    "saturation_thresh_param = (90,255)\n",
    "hue_thresh_param = (10, 80)\n",
    "ksize = -1 \n",
    "\n",
    "\n",
    "def abs_sobel_thresh(grayImg , orient ='x', sobel_kernel=-1, thresh=(50, 150)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "\n",
    "    if orient =='x':\n",
    "        sobelDir = cv2.Sobel(grayImg, cv2.CV_64F, 1,0, ksize=sobel_kernel) #x oritentaion\n",
    "    elif orient =='y':\n",
    "        sobelDir = cv2.Sobel(grayImg, cv2.CV_64F, 0,1, ksize=sobel_kernel) #y orientation\n",
    "\n",
    "    absSobelDir = np.absolute(sobelDir)\n",
    "    scaled_sobel = np.uint8(255*absSobelDir/np.max(sobelDir))\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(grayImg , sobel_kernel=-1, mag_thresh=(90, 150)):\n",
    "    # Calculate gradient magnitude\n",
    "    # Apply threshold\n",
    "    thresh_min = mag_thresh[0]\n",
    "    thresh_max = mag_thresh[1]\n",
    "    sobelx = cv2.Sobel(grayImg, cv2.CV_64F, 1,0,ksize=sobel_kernel) #x oritentaion\n",
    "    sobely = cv2.Sobel(grayImg, cv2.CV_64F, 0,1,ksize=sobel_kernel) #y orientation\n",
    "    absSobelxy = np.sqrt(sobelx**2+sobely**2)\n",
    "    scaled_sobel = np.uint8(255*absSobelxy/np.max(absSobelxy))\n",
    "    mag_binary = np.zeros_like(scaled_sobel)\n",
    "    mag_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(grayImg , sobel_kernel=-1, thresh=(0.9, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    sobelx = cv2.Sobel(grayImg, cv2.CV_64F, 1,0,ksize=sobel_kernel) #x oritentaion\n",
    "    sobely = cv2.Sobel(grayImg, cv2.CV_64F, 0,1,ksize=sobel_kernel) #y orientation\n",
    "    gradientDirectionImg = np.arctan2(np.absolute(sobely), np.absolute(sobelx));\n",
    "    dir_binary = np.zeros_like(gradientDirectionImg)\n",
    "    dir_binary[(gradientDirectionImg >= thresh_min) & (gradientDirectionImg <= thresh_max)] = 1\n",
    "    return dir_binary\n",
    "\n",
    "def color_threshold(image, S_thresh=(90, 255),H_thresh=(10, 80)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    S = hls[:,:,2]\n",
    "    color_binary = np.zeros_like(S)\n",
    "    color_binary[(S >= S_thresh[0]) & (S <= S_thresh[1])& (H >= H_thresh[0])& (H <= H_thresh[1])] = 1\n",
    "    return color_binary\n",
    "\n",
    "\n",
    "def threshold(image,ksize, abs_sobel_thresh_param_x, abs_sobel_thresh_param_y ,mag_thresh_param, dir_thresh_param,saturation_thresh_param, hue_thresh_param):\n",
    "    # Convert original RGB image to Gray Image\n",
    "    grayImg = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Gradient Threshold\n",
    "    gradx = abs_sobel_thresh(grayImg, orient='x', sobel_kernel=ksize, thresh=abs_sobel_thresh_param_x)\n",
    "    grady = abs_sobel_thresh(grayImg, orient='y', sobel_kernel=ksize, thresh=abs_sobel_thresh_param_y)\n",
    "    mag_binary = mag_thresh(grayImg, sobel_kernel=ksize, mag_thresh=mag_thresh_param)\n",
    "    dir_binary = dir_threshold(grayImg, sobel_kernel=ksize, thresh=dir_thresh_param)\n",
    "    combined_gradient_binary = np.zeros_like(dir_binary)\n",
    "    combined_gradient_binary[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    # Color Threshold\n",
    "    color_binary = color_threshold(image, S_thresh=saturation_thresh_param,H_thresh=hue_thresh_param)\n",
    "\n",
    "    # Combine Gradient Threshold and Color Threshold\n",
    "    image_after_threshold_binary = np.zeros_like(color_binary)\n",
    "    image_after_threshold_binary[(combined_gradient_binary == 1)|(color_binary == 1)]=1\n",
    "    return image_after_threshold_binary\n",
    "\n",
    "def mask_image(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "# Test threshold function:\n",
    "#d = 0 #image naming counter\n",
    "#images = glob.glob('../test_images/test*.jpg')\n",
    "#for fname in images:\n",
    "#    image =  mpimg.imread(fname)\n",
    "#    height, width, chanels = image.shape\n",
    "#    mask_vertices = np.array([[(width*0.1,height),(width/2.3,height/1.6),(width/1.7,height/1.6),(width*0.9,height)]],dtype=np.int32)\n",
    "    \n",
    "#    image_after_threshold_binary = threshold(image,ksize, abs_sobel_thresh_param_x,abs_sobel_thresh_param_y, mag_thresh_param, dir_thresh_param, saturation_thresh_param, hue_thresh_param)\n",
    "    \n",
    "#    maksed_image = mask_image(image_after_threshold_binary, mask_vertices)\n",
    "#    outputImgPath = \"./thresholded_images/\"\n",
    "#    mpimg.imsave(outputImgPath+\"thresholded_images%d.jpg\"%d,maksed_image,cmap='gray')\n",
    "#    d+=1\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transform\n",
    "To get the curvature of the road, first we need fit the lane line with a polynomial function. While this process might seem to be straight forward, we need to deal with the distortion based on the mounted postion of our camera (In this case, the camera is mounted on the hood). To accurately fit the lane line, we need to perform a perspective transform, such that the resulting image becomes a top-down view. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "d = 1 #image naming counter\n",
    "images = glob.glob('../test_images/test*.jpg')\n",
    "\n",
    "def perspective_transform(image):\n",
    "    if len(image.shape) > 2:\n",
    "        height, width, chanels = image.shape\n",
    "    else:\n",
    "        height, width = image.shape\n",
    "            \n",
    "    src = np.array([[(width*0.1,height*0.9),\n",
    "                    (width/2.3,height/1.6),\n",
    "                    (width/1.7,height/1.6),\n",
    "                    (width*0.9,height*0.9)]],dtype=np.float32)\n",
    "    \n",
    "    dst = np.array([[(0.2*width,height),\n",
    "                    (0.2*width,0),\n",
    "                    (0.8*width,0),\n",
    "                    (0.8*width,height)]],dtype=np.float32)\n",
    "    transform_matrix = cv2.getPerspectiveTransform(src,dst)\n",
    "    top_down_image = cv2.warpPerspective(image, transform_matrix, (width,height), flags = cv2.INTER_LINEAR)\n",
    "    return top_down_image, transform_matrix\n",
    "    \n",
    "\n",
    "#for fname in images:\n",
    "#    image =  mpimg.imread(fname)\n",
    "#    top_down_image, transform_matrix = perspective_transform(image)\n",
    "#    outputImgPath = \"./top_down_images/\"\n",
    "#    mpimg.imsave(outputImgPath+\"top_down_images%d.jpg\"%d,top_down_image,cmap='gray')\n",
    "#    d+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane Lines Fitting\n",
    "The next step is to fit lane line using a polynomial as the following:\n",
    "$$y = ax^2+bx+c$$\n",
    "\n",
    "Before fitting the lane line, we need to process raw images with functions that we have defined above and output thresholded, masked, transformed binary images. We name these \"warped_images\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Threshold Parameters\n",
    "abs_sobel_thresh_param_x = (50,150)\n",
    "abs_sobel_thresh_param_y = (0,25)\n",
    "mag_thresh_param = (60, 150)\n",
    "dir_thresh_param = (0.9, np.pi/2)\n",
    "saturation_thresh_param = (90,255)\n",
    "hue_thresh_param = (10, 80)\n",
    "ksize = -1 \n",
    "#mask_vertices = np.array([[(width*0.1,height*0.9),(width/2.3,height/1.6),(width/1.7,height/1.6),(width*0.9,height*0.9)]],dtype=np.int32)\n",
    "\n",
    "\n",
    "# Read in images\n",
    "#d = 1\n",
    "#images = glob.glob('../test_images/test*.jpg')\n",
    "\n",
    "# Loop Through images \n",
    "#for fname in images:\n",
    "#    image =  mpimg.imread(fname)\n",
    "#    height, width, chanels = image.shape\n",
    "#    image_after_threshold_binary = threshold(image,ksize, abs_sobel_thresh_param_x,abs_sobel_thresh_param_y, mag_thresh_param, dir_thresh_param, saturation_thresh_param, hue_thresh_param)\n",
    "#    maksed_image_binary = mask_image(image_after_threshold_binary, mask_vertices)\n",
    "#    top_down_image = perspective_transform(maksed_image_binary)\n",
    "#    outputImgPath = \"./images_for_lane_lines_fitting/\"\n",
    "#    mpimg.imsave(outputImgPath+\"warped_images%d.jpg\"%d,top_down_image,cmap='gray')\n",
    "#    d += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have created warped_images for testing. I am using a slidng window apporach to fit the lane lines. For each lane line, we will have n windows each (In total, we have $2\\times n$ windows for the entire image). To determine the starting point of left lane line and right lane line, we will sum the number of pixels vertically along bottom of the image. The histogram will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    #binary_warped = binary_warped[:,:,0] #Just get the one of the three channels\n",
    "    \n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = (np.dstack((binary_warped, binary_warped, binary_warped))).astype(np.uint8)\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "    \n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    \n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    #plt.imshow(out_img)\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return left_fit, right_fit, ploty, leftx, lefty, rightx, righty, left_fitx, right_fitx\n",
    "\n",
    "#images = glob.glob('./images_for_lane_lines_fitting/warped_images*.jpg')\n",
    "#d=0\n",
    "#for fname in images:\n",
    "#    test_warped_image =  mpimg.imread(fname)\n",
    "#    sliding_window_img, left_fit, right_fit = fit_polynomial(test_warped_image)\n",
    "#    outputImgPath = \"./sliding_window_images/\"\n",
    "#    mpimg.imsave(outputImgPath+\"sliding_window_images%d.jpg\"%d,sliding_window_img)\n",
    "#    d += 1\n",
    "\n",
    "#test_warped_image = mpimg.imread('./images_for_lane_lines_fitting/warped_images5.jpg')\n",
    "#sliding_window_img, left_fit, right_fit = fit_polynomial(test_warped_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up process of finding lane line on the next frame,we utlizes the prior knowdge of where lane line could possibly be located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitpolynomial_with_previous_fitting_value(binary_warped, left_fit_before, right_fit_before):\n",
    "    margin = 120\n",
    "    left_fit_current, right_fit_current = (None, None)\n",
    "    img_shape = binary_warped.shape\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit_before[0]*(nonzeroy**2) + left_fit_before[1]*nonzeroy + \n",
    "                    left_fit_before[2] - margin)) & (nonzerox < (left_fit_before[0]*(nonzeroy**2) + \n",
    "                    left_fit_before[1]*nonzeroy + left_fit_before[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit_before[0]*(nonzeroy**2) + right_fit_before[1]*nonzeroy + \n",
    "                    right_fit_before[2] - margin)) & (nonzerox < (right_fit_before[0]*(nonzeroy**2) + \n",
    "                    right_fit_before[1]*nonzeroy + right_fit_before[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    left_fit_current = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit_current = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty_current = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx_current = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx_currents = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fit_current, right_fit_current, ploty, leftx, lefty, rightx, righty\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radius Curvature Calculation\n",
    "\n",
    "The radius curvature formula is the following: \n",
    "$$R_{curve} = \\frac{(1+(2ay+b)^2)^{\\frac{3}{2}}}{|2a|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def measure_curvature_pixels(left_fit, right_fit, ploty, leftx, lefty, rightx, righty):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in pixels.\n",
    "    '''    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def measured_curvature_meters(left_fit, right_fit, ploty, leftx, lefty, rightx, righty):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''  \n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    leftx = leftx[::-1]   # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    \n",
    "    # Determine center position, assuming image 1280x720\n",
    "    leftx_mid = left_fit[0]*720**2 + left_fit[1]*720 + left_fit[2]\n",
    "    rightx_mid = right_fit[0]*720**2 + right_fit[1]*720 + right_fit[2]\n",
    "    center_offset_meter = abs((640-(rightx_mid+leftx_mid)/2)*xm_per_pix)\n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad,center_offset_meter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "\n",
    "def draw_line(undistortedImg, transform_matrix, top_down_image, ploty, left_fitx, right_fitx, left_curverad_meter,right_curverad_meter, center_offset_meter):\n",
    "    warp_zero = np.zeros_like(top_down_image).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    Minv = np.linalg.inv(transform_matrix)\n",
    "    \n",
    "    # Generate Points\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (undistortedImg.shape[1], undistortedImg.shape[0])) \n",
    "    result_image = cv2.addWeighted(undistortedImg, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    # Display Informtiaon on Image\n",
    "    cv2.putText(result_image, 'Left Lane Curve: '+str(\"{0:.2f}\".format(left_curverad_meter)) + ' meter', (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "    cv2.putText(result_image, 'Right Lane Curve: '+str(\"{0:.2f}\".format(right_curverad_meter)) + ' meter', (100,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "    cv2.putText(result_image, 'Center Offset: '+str(\"{0:.2f}\".format(center_offset_meter)) + ' meter', (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Pipe Line Testing\n",
    "Now let us test out the lane line detection algorithm on real videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f65c40b1c88>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "\n",
    "# Load Test Image\n",
    "pipe_image_example = mpimg.imread('../test_images/test6.jpg')\n",
    "height, width, channel = pipe_image_example.shape\n",
    "# Load Camera Calibration Matrix and Distortion Coefficients\n",
    "mtx = genfromtxt('camera_calibration_matrix.csv',delimiter=',',encoding=\"utf8\")\n",
    "dist = genfromtxt('camera_distortion_coefficients.csv',delimiter=',',encoding=\"utf8\")\n",
    "\n",
    "\n",
    "# Threshold Parameters\n",
    "abs_sobel_thresh_param_x = (50,150)\n",
    "abs_sobel_thresh_param_y = (0,25)\n",
    "mag_thresh_param = (60, 150)\n",
    "dir_thresh_param = (0.9, np.pi/2)\n",
    "saturation_thresh_param = (90,255)\n",
    "hue_thresh_param = (10, 80)\n",
    "ksize = -1 \n",
    "mask_vertices = np.array([[(width*0.1,height*0.9),(width/2.3,height/1.6),(width/1.7,height/1.6),(width*0.9,height*0.9)]],dtype=np.int32)\n",
    "\n",
    "def pipeline(image):\n",
    "    # Acquire image shape\n",
    "    height, width, chanels = image.shape\n",
    "    # Undistort Image\n",
    "    undistortedImg = cv2.undistort(image,mtx,dist, None, mtx)\n",
    "    # Apply Threshold to remove unwanted background pixels\n",
    "    image_after_threshold_binary = threshold(undistortedImg,ksize, abs_sobel_thresh_param_x,abs_sobel_thresh_param_y, mag_thresh_param, dir_thresh_param, saturation_thresh_param, hue_thresh_param)\n",
    "    # Masking to get region of interst\n",
    "    maksed_image_binary = mask_image(image_after_threshold_binary, mask_vertices)\n",
    "\n",
    "    # Perspective Transform to top down view\n",
    "    top_down_image, transform_matrix = perspective_transform(maksed_image_binary)\n",
    "    # Use sliding window technique to acquire polynomial coefficent for line fitting\n",
    "    left_fit, right_fit, ploty, leftx, lefty, rightx, righty, left_fitx, right_fitx = fit_polynomial(top_down_image)\n",
    "    # Calculate Curvature in pixel\n",
    "    #left_curverad_pixel, right_curverad_pixel = measure_curvature_pixels(left_fit, right_fit, ploty, leftx, lefty, rightx, righty)\n",
    "    #return left_curverad_pixel, right_curverad_pixel\n",
    "    left_curverad_meter, right_curverad_meter, center_offset_meter = measured_curvature_meters(left_fit, right_fit, ploty, leftx, lefty, rightx, righty)\n",
    "    result_image = draw_line(undistortedImg, transform_matrix, top_down_image, ploty, left_fitx, right_fitx,left_curverad_meter,right_curverad_meter, center_offset_meter)\n",
    "    return result_image\n",
    "\n",
    "result_image = pipeline(pipe_image_example)\n",
    "#plt.imshow(result_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_output = '../output_video/project_output.mp4'\n",
    "project_video = VideoFileClip('../project_video.mp4')\n",
    "processed_video = project_video.fl_image(pipeline)\n",
    "%time processed_video.write_videofile(test_video_output, audio = False, verbose=False,progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"1280\" height=\"740\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(processed_video))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
